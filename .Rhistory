file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
} else{ # use USGS package to pull data from web, then save locally
start <- ymd_hms("2018-01-01 00:00:00")
end <- ymd_hms("2018-06-15 00:00:00")
if(sitename == "Desoto"){
siteNo <- "06892350"
pCodes <- c("99133", "00060", "00065", "00300", "00301","00010",
"00095", "00400", "32295", "32318")
# 99133 = nitrate + nitrite [mg-N/L]
# 00060 = discharge [cfs]
# 00065 = gage height [ft]
# 00300 = dissolved oxygen [mg/L]
# 00301 = dissolved oxygen [% saturation]
# 00010 = water temperature [C]
# 00095 = specific conductance at 25C
# 00400 = pH
# 32295 = fDOM
# 32318 = chlorophyll
}
data <- readNWISuv(siteNumbers = siteNo, parameterCd = pCodes,
startDate = start, endDate = end, tz = "America/Chicago")
# Rename columns from codes to parameter names
data <- renameNWISColumns(data)
# Fix remaining names that are still parameter codes
names(data)[names(data)=="00301_Inst"] <- "DO_percentsat"
names(data)[names(data)=="00301_Inst_cd"] <- "DO_percentsat_cd"
names(data)[names(data)=="99133_Inst"] <- "nitrateNitrite"
names(data)[names(data)=="99133_Inst_cd"] <- "nitrateNitrite_cd"
# Convert from American to SI units
# cubic foot per second to liters per second
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
# foot to meters
ft_m <- function(ft){
m <- 0.3048*ft
return(m)
}
data$Flow_Inst <- ft3s_m3s(data$Flow_Inst)
data$GH_Inst <- ft_m(data$GH_Inst)
# save the USGS data locally
write.csv(data, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
dataframe <- data
}
return(dataframe)
}
desoto <- masterFile(sitename = "Desoto", USGS = TRUE)
masterFile <- function(sitename, USGS){
if(!file.exists(paste("KAWN_Sensors_", sitename, sep = ""))){
# if master file doesn't exist, compile master file
if(USGS == FALSE){
# load in nitratax data
nitratax_XMLtoCSV <- function(filename){
xmlData <- XML::xmlParse(file = filename)
xmlData <- XML::xmlToDataFrame(xmlData, homogeneous = F, stringsAsFactors = F)
xmlData <- xmlData[-(1:6),] # taking out text at top of dataframe
for (count in 1:length(xmlData)){
names(xmlData)[count] <- as.character(xmlData[1,count])
}
xmlData <- xmlData[-1,] # taking out character rows
xmlData <- xmlData[,-1] # taking out first blank column
xmlData$`  TIME  ` <- lubridate::as_datetime(xmlData$`  TIME  `,
tz = "America/Chicago",
format = "%m/%d/%Y %H:%M:%S")
xmlData$`  NITRATE CONC.  ` <- as.numeric(xmlData$`  NITRATE CONC.  `)
xmlData$`  ER  ` <- as.numeric(xmlData$`  ER  `)
xmlData$`  EM  ` <- as.numeric(xmlData$`  EM  `)
xmlData <- data.frame(xmlData$`  TIME  `, xmlData$`  NITRATE CONC.  `)
names(xmlData) <- c("dateTime", "nitrateNitrite")
return(xmlData)
}
nitratax <- nitratax_XMLtoCSV(paste("NITRATAX_", sitename, ".xml", sep = ""))
if(file.exists(paste("miniDOT_", sitename, ".txt", sep = ""))){
# load in minidot data
DO <- read.table(file = paste("miniDOT_", sitename, ".txt", sep = ""),
header = TRUE, sep = ",", skip = 8, stringsAsFactors = FALSE,
colClasses = c("numeric", "POSIXct", "POSIXct", "numeric",
"numeric", "numeric", "numeric", "numeric"),
col.names = c("unixTimestamp", "time_UTC", "time_CST",
"battery_V", "temp_C", "DO_mgL", "DO_sat", "Q"))
DO <- DO[c(-1, -2, -4, -8)] #drop unix timestamp, time UTC, battery volts, Q
DO$time_CST <- round_date(DO$time_CST, unit = "5 mins") # round time to nearest 5 min
# merge minidot with nitratax by datetime
dataframe <- merge(nitratax, DO, by.x = "dateTime", by.y = "time_CST", all = TRUE)
# save master file
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
} else{
# save master file with just nitratax
dataframe <- nitratax
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
} else{ # use USGS package to pull data from web, then save locally
start <- ymd_hms("2018-01-01 00:00:00")
end <- ymd_hms("2018-06-15 00:00:00")
if(sitename == "Desoto"){
siteNo <- "06892350"
pCodes <- c("99133", "00060", "00065", "00300", "00301","00010",
"00095", "00400", "32295", "32318")
data <- readNWISuv(siteNumbers = siteNo, parameterCd = pCodes,
startDate = start, endDate = end, tz = "America/Chicago")
# Rename columns from codes to readable names
data <- renameNWISColumns(data)
# Fix remaining names that are still parameter codes
names(data)[names(data)=="00301_Inst"] <- "DO_percentsat"
names(data)[names(data)=="00301_Inst_cd"] <- "DO_percentsat_cd"
names(data)[names(data)=="99133_Inst"] <- "nitrateNitrite"
names(data)[names(data)=="99133_Inst_cd"] <- "nitrateNitrite_cd"
# Convert from American to SI units
# cubic foot per second to liters per second
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
# foot to meters
ft_m <- function(ft){
m <- 0.3048*ft
return(m)
}
data$Flow_Inst <- ft3s_m3s(data$Flow_Inst)
data$GH_Inst <- ft_m(data$GH_Inst)
# drop agency code, siteNo, various quality codes
dataframe <- data[c(-1,-2,-5,-7,-9,-11,-13,-15,-17,-19,-21,-22)]
}
# save the USGS data locally
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
return(dataframe)
}
desoto <- masterFile(sitename = "Desoto", USGS = TRUE)
# masterFile
# concatenates local nitratax, miniDOT files into a single master .csv (if no master exists). If data is located on USGS database, pulls from USGS database and saves local master. If local master is present, script loads from file
# sitename = character vector with proper capitalization
# USGS = logical vector, if TRUE data should is pulled from USGS, if FALSE data is loaded from local files
masterFile <- function(sitename, USGS){
if(!file.exists(paste("KAWN_Sensors_", sitename, sep = ""))){
# if master file doesn't exist, compile master file
if(USGS == FALSE){
# load in nitratax data
nitratax_XMLtoCSV <- function(filename){
xmlData <- XML::xmlParse(file = filename)
xmlData <- XML::xmlToDataFrame(xmlData, homogeneous = F, stringsAsFactors = F)
xmlData <- xmlData[-(1:6),] # taking out text at top of dataframe
for (count in 1:length(xmlData)){
names(xmlData)[count] <- as.character(xmlData[1,count])
}
xmlData <- xmlData[-1,] # taking out character rows
xmlData <- xmlData[,-1] # taking out first blank column
xmlData$`  TIME  ` <- lubridate::as_datetime(xmlData$`  TIME  `,
tz = "America/Chicago",
format = "%m/%d/%Y %H:%M:%S")
xmlData$`  NITRATE CONC.  ` <- as.numeric(xmlData$`  NITRATE CONC.  `)
xmlData$`  ER  ` <- as.numeric(xmlData$`  ER  `)
xmlData$`  EM  ` <- as.numeric(xmlData$`  EM  `)
xmlData <- data.frame(xmlData$`  TIME  `, xmlData$`  NITRATE CONC.  `)
names(xmlData) <- c("dateTime", "nitrateNitrite")
return(xmlData)
}
nitratax <- nitratax_XMLtoCSV(paste("NITRATAX_", sitename, ".xml", sep = ""))
if(file.exists(paste("miniDOT_", sitename, ".txt", sep = ""))){
# load in minidot data
DO <- read.table(file = paste("miniDOT_", sitename, ".txt", sep = ""),
header = TRUE, sep = ",", skip = 8, stringsAsFactors = FALSE,
colClasses = c("numeric", "POSIXct", "POSIXct", "numeric",
"numeric", "numeric", "numeric", "numeric"),
col.names = c("unixTimestamp", "time_UTC", "time_CST",
"battery_V", "temp_C", "DO_mgL", "DO_sat", "Q"))
DO <- DO[c(-1, -2, -4, -8)] #drop unix timestamp, time UTC, battery volts, Q
DO$time_CST <- round_date(DO$time_CST, unit = "5 mins") # round time to nearest 5 min
# merge minidot with nitratax by datetime
dataframe <- merge(nitratax, DO, by.x = "dateTime", by.y = "time_CST", all = TRUE)
# save master file
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
} else{
# save master file with just nitratax
dataframe <- nitratax
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
} else{ # use USGS package to pull data from web, then save locally
start <- ymd_hms("2018-01-01 00:00:00")
end <- ymd_hms("2018-06-15 00:00:00")
if(sitename == "Desoto"){
siteNo <- "06892350"
pCodes <- c("99133", "00060", "00065", "00300", "00301","00010",
"00095", "00400", "32295", "32318")
data <- readNWISuv(siteNumbers = siteNo, parameterCd = pCodes,
startDate = start, endDate = end, tz = "America/Chicago")
# Rename columns from codes to readable names
data <- renameNWISColumns(data)
# Fix remaining names that are still parameter codes
names(data)[names(data)=="00301_Inst"] <- "DO_percentsat"
names(data)[names(data)=="00301_Inst_cd"] <- "DO_percentsat_cd"
names(data)[names(data)=="99133_Inst"] <- "nitrateNitrite"
names(data)[names(data)=="99133_Inst_cd"] <- "nitrateNitrite_cd"
# Convert from American to SI units
# cubic foot per second to liters per second
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
# foot to meters
ft_m <- function(ft){
m <- 0.3048*ft
return(m)
}
data$Flow_Inst <- ft3s_m3s(data$Flow_Inst)
data$GH_Inst <- ft_m(data$GH_Inst)
# drop agency code, siteNo, various quality codes
dataframe <- data[c(-1,-2,-5,-7,-9,-11,-13,-15,-17,-19,-21,-22)]
}
# save the USGS data locally
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
if(file.exists(paste("KAWN_Sensors_", sitename, sep = ""))){
dataframe <- read.csv(paste("KAWN_Sensors_", sitename, sep = ""), header = TRUE)
}
return(dataframe)
}
bowersock <- masterFile(sitename = "Bowersock", USGS = FALSE)
# masterFile
# concatenates local nitratax, miniDOT files into a single master .csv (if no master exists). If data is located on USGS database, pulls from USGS database and saves local master. If local master is present, script loads from file
# sitename = character vector with proper capitalization
# USGS = logical vector, if TRUE data should is pulled from USGS, if FALSE data is loaded from local files
masterFile <- function(sitename, USGS){
if(!file.exists(paste("KAWN_Sensors_", sitename, sep = ""))){
# if master file doesn't exist, compile master file
if(USGS == FALSE){
# load in nitratax data
nitratax_XMLtoCSV <- function(filename){
xmlData <- XML::xmlParse(file = filename)
xmlData <- XML::xmlToDataFrame(xmlData, homogeneous = F, stringsAsFactors = F)
xmlData <- xmlData[-(1:6),] # taking out text at top of dataframe
for (count in 1:length(xmlData)){
names(xmlData)[count] <- as.character(xmlData[1,count])
}
xmlData <- xmlData[-1,] # taking out character rows
xmlData <- xmlData[,-1] # taking out first blank column
xmlData$`  TIME  ` <- lubridate::as_datetime(xmlData$`  TIME  `,
tz = "America/Chicago",
format = "%m/%d/%Y %H:%M:%S")
xmlData$`  NITRATE CONC.  ` <- as.numeric(xmlData$`  NITRATE CONC.  `)
xmlData$`  ER  ` <- as.numeric(xmlData$`  ER  `)
xmlData$`  EM  ` <- as.numeric(xmlData$`  EM  `)
xmlData <- data.frame(xmlData$`  TIME  `, xmlData$`  NITRATE CONC.  `)
names(xmlData) <- c("dateTime", "nitrateNitrite")
return(xmlData)
}
nitratax <- nitratax_XMLtoCSV(paste("NITRATAX_", sitename, ".xml", sep = ""))
if(file.exists(paste("miniDOT_", sitename, ".txt", sep = ""))){
# load in minidot data
DO <- read.table(file = paste("miniDOT_", sitename, ".txt", sep = ""),
header = TRUE, sep = ",", skip = 8, stringsAsFactors = FALSE,
colClasses = c("numeric", "POSIXct", "POSIXct", "numeric",
"numeric", "numeric", "numeric", "numeric"),
col.names = c("unixTimestamp", "time_UTC", "time_CST",
"battery_V", "temp_C", "DO_mgL", "DO_sat", "Q"))
DO <- DO[c(-1, -2, -4, -8)] #drop unix timestamp, time UTC, battery volts, Q
DO$time_CST <- round_date(DO$time_CST, unit = "5 mins") # round time to nearest 5 min
# merge minidot with nitratax by datetime
dataframe <- merge(nitratax, DO, by.x = "dateTime", by.y = "time_CST", all = TRUE)
# save master file
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
} else{
# save master file with just nitratax
dataframe <- nitratax
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
} else{ # use USGS package to pull data from web, then save locally
start <- ymd_hms("2018-01-01 00:00:00")
end <- ymd_hms("2018-06-15 00:00:00")
if(sitename == "Desoto"){
siteNo <- "06892350"
pCodes <- c("99133", "00060", "00065", "00300", "00301","00010",
"00095", "00400", "32295", "32318")
data <- readNWISuv(siteNumbers = siteNo, parameterCd = pCodes,
startDate = start, endDate = end, tz = "America/Chicago")
# Rename columns from codes to readable names
data <- renameNWISColumns(data)
# Fix remaining names that are still parameter codes
names(data)[names(data)=="00301_Inst"] <- "DO_percentsat"
names(data)[names(data)=="00301_Inst_cd"] <- "DO_percentsat_cd"
names(data)[names(data)=="99133_Inst"] <- "nitrateNitrite"
names(data)[names(data)=="99133_Inst_cd"] <- "nitrateNitrite_cd"
# Convert from American to SI units
# cubic foot per second to liters per second
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
# foot to meters
ft_m <- function(ft){
m <- 0.3048*ft
return(m)
}
data$Flow_Inst <- ft3s_m3s(data$Flow_Inst)
data$GH_Inst <- ft_m(data$GH_Inst)
# drop agency code, siteNo, various quality codes
dataframe <- data[c(-1,-2,-5,-7,-9,-11,-13,-15,-17,-19,-21,-22)]
}
# save the USGS data locally
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
if(file.exists(paste("KAWN_Sensors_", sitename, sep = ""))){
dataframe <- read.csv(paste("KAWN_Sensors_", sitename, sep = ""), header = TRUE)
}
return(dataframe)
}
bowersock <- masterFile(sitename = "Bowersock", USGS = FALSE)
eric <- masterFile(sitename = "Eric", USGS = FALSE)
steve <- masterFile(sitename = "Steve", USGS = FALSE)
desoto <- masterFile(sitename = "Desoto", USGS = TRUE)
file.exists(paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
file.exists(paste("KAWN_Sensors_", "Desoto", ".csv", sep = ""))
!file.exists(paste("KAWN_Sensors_", "Desoto", ".csv", sep = ""))
desoto2 <- read.csv(paste("KAWN_Sensors_", "Desoto", ".csv", sep = ""))
masterFile <- function(sitename, USGS){
if(file.exists(paste("KAWN_Sensors_", sitename, ".csv", sep = ""))){
dataframe <- read.csv(paste("KAWN_Sensors_", sitename, ".csv", sep = ""), header = TRUE)
}
if(!file.exists(paste("KAWN_Sensors_", sitename, ".csv", sep = ""))){
# if master file doesn't exist, compile master file
if(USGS == FALSE){
# load in nitratax data
nitratax_XMLtoCSV <- function(filename){
xmlData <- XML::xmlParse(file = filename)
xmlData <- XML::xmlToDataFrame(xmlData, homogeneous = F, stringsAsFactors = F)
xmlData <- xmlData[-(1:6),] # taking out text at top of dataframe
for (count in 1:length(xmlData)){
names(xmlData)[count] <- as.character(xmlData[1,count])
}
xmlData <- xmlData[-1,] # taking out character rows
xmlData <- xmlData[,-1] # taking out first blank column
xmlData$`  TIME  ` <- lubridate::as_datetime(xmlData$`  TIME  `,
tz = "America/Chicago",
format = "%m/%d/%Y %H:%M:%S")
xmlData$`  NITRATE CONC.  ` <- as.numeric(xmlData$`  NITRATE CONC.  `)
xmlData$`  ER  ` <- as.numeric(xmlData$`  ER  `)
xmlData$`  EM  ` <- as.numeric(xmlData$`  EM  `)
xmlData <- data.frame(xmlData$`  TIME  `, xmlData$`  NITRATE CONC.  `)
names(xmlData) <- c("dateTime", "nitrateNitrite")
return(xmlData)
}
nitratax <- nitratax_XMLtoCSV(paste("NITRATAX_", sitename, ".xml", sep = ""))
if(file.exists(paste("miniDOT_", sitename, ".txt", sep = ""))){
# load in minidot data
DO <- read.table(file = paste("miniDOT_", sitename, ".txt", sep = ""),
header = TRUE, sep = ",", skip = 8, stringsAsFactors = FALSE,
colClasses = c("numeric", "POSIXct", "POSIXct", "numeric",
"numeric", "numeric", "numeric", "numeric"),
col.names = c("unixTimestamp", "time_UTC", "time_CST",
"battery_V", "temp_C", "DO_mgL", "DO_sat", "Q"))
DO <- DO[c(-1, -2, -4, -8)] #drop unix timestamp, time UTC, battery volts, Q
DO$time_CST <- round_date(DO$time_CST, unit = "5 mins") # round time to nearest 5 min
# merge minidot with nitratax by datetime
dataframe <- merge(nitratax, DO, by.x = "dateTime", by.y = "time_CST", all = TRUE)
# save master file
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
} else{
# save master file with just nitratax
dataframe <- nitratax
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
} else{ # use USGS package to pull data from web, then save locally
start <- ymd_hms("2018-01-01 00:00:00")
end <- ymd_hms("2018-06-15 00:00:00")
if(sitename == "Desoto"){
siteNo <- "06892350"
pCodes <- c("99133", "00060", "00065", "00300", "00301","00010",
"00095", "00400", "32295", "32318")
data <- readNWISuv(siteNumbers = siteNo, parameterCd = pCodes,
startDate = start, endDate = end, tz = "America/Chicago")
# Rename columns from codes to readable names
data <- renameNWISColumns(data)
# Fix remaining names that are still parameter codes
names(data)[names(data)=="00301_Inst"] <- "DO_percentsat"
names(data)[names(data)=="00301_Inst_cd"] <- "DO_percentsat_cd"
names(data)[names(data)=="99133_Inst"] <- "nitrateNitrite"
names(data)[names(data)=="99133_Inst_cd"] <- "nitrateNitrite_cd"
# Convert from American to SI units
# cubic foot per second to liters per second
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
# foot to meters
ft_m <- function(ft){
m <- 0.3048*ft
return(m)
}
data$Flow_Inst <- ft3s_m3s(data$Flow_Inst)
data$GH_Inst <- ft_m(data$GH_Inst)
# drop agency code, siteNo, various quality codes
dataframe <- data[c(-1,-2,-5,-7,-9,-11,-13,-15,-17,-19,-21,-22)]
}
# save the USGS data locally
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_Sensors_", sitename, ".csv", sep = ""))
}
return(dataframe)
}
desoto <- masterFile(sitename = "Desoto", USGS = TRUE)
desoto4 <- masterFile(sitename = "Desoto", USGS = TRUE)
# masterFile
# concatenates local nitratax, miniDOT files into a single master .csv (if no master exists). If data is located on USGS database, pulls from USGS database and saves local master. If local master is present, script loads from file
# sitename = character vector with proper capitalization
# USGS = logical vector, if TRUE data should is pulled from USGS, if FALSE data is loaded from local files
masterFile <- function(sitename, USGS){
if(file.exists(paste("KAWN_SensorData_", sitename, ".csv", sep = ""))){
# if master file exists, load from master file
dataframe <- read.csv(paste("KAWN_SensorData_", sitename, ".csv", sep = ""),
header = TRUE)
}
if(!file.exists(paste("KAWN_SensorData_", sitename, ".csv", sep = ""))){
# if master file doesn't exist, compile master file
if(USGS == FALSE){
# load in nitratax data
nitratax_XMLtoCSV <- function(filename){
xmlData <- XML::xmlParse(file = filename)
xmlData <- XML::xmlToDataFrame(xmlData, homogeneous = F, stringsAsFactors = F)
xmlData <- xmlData[-(1:6),] # taking out text at top of dataframe
for (count in 1:length(xmlData)){
names(xmlData)[count] <- as.character(xmlData[1,count])
}
xmlData <- xmlData[-1,] # taking out character rows
xmlData <- xmlData[,-1] # taking out first blank column
xmlData$`  TIME  ` <- lubridate::as_datetime(xmlData$`  TIME  `,
tz = "America/Chicago",
format = "%m/%d/%Y %H:%M:%S")
xmlData$`  NITRATE CONC.  ` <- as.numeric(xmlData$`  NITRATE CONC.  `)
xmlData$`  ER  ` <- as.numeric(xmlData$`  ER  `)
xmlData$`  EM  ` <- as.numeric(xmlData$`  EM  `)
xmlData <- data.frame(xmlData$`  TIME  `, xmlData$`  NITRATE CONC.  `)
names(xmlData) <- c("dateTime", "nitrateNitrite")
return(xmlData)
}
nitratax <- nitratax_XMLtoCSV(paste("NITRATAX_", sitename, ".xml", sep = ""))
if(file.exists(paste("miniDOT_", sitename, ".txt", sep = ""))){
# load in minidot data
DO <- read.table(file = paste("miniDOT_", sitename, ".txt", sep = ""),
header = TRUE, sep = ",", skip = 8, stringsAsFactors = FALSE,
colClasses = c("numeric", "POSIXct", "POSIXct", "numeric",
"numeric", "numeric", "numeric", "numeric"),
col.names = c("unixTimestamp", "time_UTC", "time_CST",
"battery_V", "temp_C", "DO_mgL", "DO_sat", "Q"))
DO <- DO[c(-1, -2, -4, -8)] #drop unix timestamp, time UTC, battery volts, Q
DO$time_CST <- round_date(DO$time_CST, unit = "5 mins") # round time to nearest 5 min
# merge minidot with nitratax by datetime
dataframe <- merge(nitratax, DO, by.x = "dateTime", by.y = "time_CST", all = TRUE)
# save master file
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
} else{
# save master file with just nitratax
dataframe <- nitratax
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
}
} else{ # use USGS package to pull data from web, then save locally
start <- ymd_hms("2018-01-01 00:00:00")
end <- ymd_hms("2018-06-15 00:00:00")
if(sitename == "Desoto"){
siteNo <- "06892350"
pCodes <- c("99133", "00060", "00065", "00300", "00301","00010",
"00095", "00400", "32295", "32318")
data <- readNWISuv(siteNumbers = siteNo, parameterCd = pCodes,
startDate = start, endDate = end, tz = "America/Chicago")
# Rename columns from codes to readable names
data <- renameNWISColumns(data)
# Fix remaining names that are still parameter codes
names(data)[names(data)=="00301_Inst"] <- "DO_percentsat"
names(data)[names(data)=="00301_Inst_cd"] <- "DO_percentsat_cd"
names(data)[names(data)=="99133_Inst"] <- "nitrateNitrite"
names(data)[names(data)=="99133_Inst_cd"] <- "nitrateNitrite_cd"
# Convert from American to SI units
# cubic foot per second to liters per second
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
# foot to meters
ft_m <- function(ft){
m <- 0.3048*ft
return(m)
}
data$Flow_Inst <- ft3s_m3s(data$Flow_Inst)
data$GH_Inst <- ft_m(data$GH_Inst)
# drop agency code, siteNo, various quality codes
dataframe <- data[c(-1,-2,-5,-7,-9,-11,-13,-15,-17,-19,-21,-22)]
}
# save the USGS data locally
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
}
return(dataframe)
}
bowersock <- masterFile(sitename = "Bowersock", USGS = FALSE)
eric <- masterFile(sitename = "Eric", USGS = FALSE)
steve <- masterFile(sitename = "Steve", USGS = FALSE)
desoto <- masterFile(sitename = "Desoto", USGS = TRUE)
