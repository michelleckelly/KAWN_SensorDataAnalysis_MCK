xmlData$`  NITRATE CONC.  ` <- as.numeric(xmlData$`  NITRATE CONC.  `)
xmlData$`  ER  ` <- as.numeric(xmlData$`  ER  `)
xmlData$`  EM  ` <- as.numeric(xmlData$`  EM  `)
xmlData <- data.frame(xmlData$`  TIME  `, xmlData$`  NITRATE CONC.  `)
names(xmlData) <- c("dateTime", "nitrateNitrite")
return(xmlData)
}
nitratax <- nitratax_XMLtoCSV(paste("NITRATAX_", sitename, ".xml", sep = ""))
if(file.exists(paste("miniDOT_", sitename, ".txt", sep = ""))){
# load in minidot data
DO <- read.table(file = paste("miniDOT_", sitename, ".txt", sep = ""),
header = TRUE, sep = ",", skip = 8, stringsAsFactors = FALSE,
colClasses = c("numeric", "POSIXct", "POSIXct", "numeric",
"numeric", "numeric", "numeric", "numeric"),
col.names = c("unixTimestamp", "time_UTC", "time_CST",
"battery_V", "temp_C", "DO_mgL", "DO_sat", "Q"))
DO <- DO[c(-1, -2, -4, -8)] #drop unix timestamp, time UTC, battery volts, Q
DO$time_CST <- round_date(DO$time_CST, unit = "5 mins") # round time to nearest 5 min
# merge minidot with nitratax by datetime
dataframe <- merge(nitratax, DO, by.x = "dateTime", by.y = "time_CST", all = TRUE)
# save master file
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
} else{
# save master file with just nitratax
dataframe <- nitratax
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
}
} else{ # use USGS package to pull data from web, then save locally
start <- ymd_hms("2018-01-01 00:00:00")
end <- ymd_hms("2018-06-15 00:00:00")
if(sitename == "Desoto"){
siteNo <- "06892350"
pCodes <- c("99133", "00060", "00065", "00300", "00301","00010",
"00095", "00400", "32295", "32318")
data <- readNWISuv(siteNumbers = siteNo, parameterCd = pCodes,
startDate = start, endDate = end, tz = "America/Chicago")
# Rename columns from codes to readable names
data <- renameNWISColumns(data)
# Fix remaining names that are still parameter codes
names(data)[names(data)=="00301_Inst"] <- "DO_percentsat"
names(data)[names(data)=="00301_Inst_cd"] <- "DO_percentsat_cd"
names(data)[names(data)=="99133_Inst"] <- "nitrateNitrite"
names(data)[names(data)=="99133_Inst_cd"] <- "nitrateNitrite_cd"
# Convert from American to SI units
# cubic foot per second to liters per second
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
# foot to meters
ft_m <- function(ft){
m <- 0.3048*ft
return(m)
}
data$Flow_Inst <- ft3s_m3s(data$Flow_Inst)
data$GH_Inst <- ft_m(data$GH_Inst)
# drop agency code, siteNo, various quality codes
dataframe <- data[c(-1,-2,-5,-7,-9,-11,-13,-15,-17,-19,-21,-22)]
}
# save the USGS data locally
write.csv(dataframe, row.names = FALSE,
file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
}
return(dataframe)
}
bowersock <- masterFile(sitename = "Bowersock", USGS = FALSE)
eric <- masterFile(sitename = "Eric", USGS = FALSE)
steve <- masterFile(sitename = "Steve", USGS = FALSE)
desoto <- masterFile(sitename = "Desoto", USGS = TRUE)
unlink('KAWN_Sensors_DataLoading_cache', recursive = TRUE)
knitr::opts_chunk$set(cache=TRUE)
library(XML)
library(lubridate)
library(data.table)
library(dplyr)
library(tidyr)
library(dataRetrieval) # USGS loading
# NEON loading
# library(devtools)
# install_github("NEONScience/NEON-utilities/neonUtilities", dependencies = TRUE)
library(neonUtilities)
# avg.Q: logical, TRUE returns dataframe of mean daily Q at all sites, FALSE returns all measurements of Q at all sites
# load from file: logical, if TRUE loads appropriate dataframe from file
Q.dataframe <- function(avg.Q, loadfromfile){
if(avg.Q = TRUE && file.exists("KAWN_USGSDischarge_dailymeans.csv")){
# avg.Q: logical, TRUE returns dataframe of mean daily Q at all sites, FALSE returns all measurements of Q at all sites
# load from file: logical, if TRUE loads appropriate dataframe from file
Q.dataframe <- function(avg.Q){
if(avg.Q == TRUE && file.exists("KAWN_USGSDischarge_dailymeans.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_dailymeans.csv", header = TRUE)
}
if(avg.Q == FALSE && file.exists("KAWN_USGSDischarge_instantaneous.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_instantaneous.csv", header = TRUE)
}
if(!file.exists("KAWN_USGSDischarge_dailymeans.csv") | !file.exists(file.exists("KAWN_USGSDischarge_dailymeans.csv"))){
Q1.lawrence <- "06891080" # USGS identifier codes for gauges of interest
Q3.wakarusa <- "06891500"
Q4.stranger <- "06892000"
Q5.desoto <- "06892350"
sites <- c(Q1.lawrence, Q3.wakarusa, Q4.stranger, Q5.desoto)
start <- ymd_hms("2018-01-01 00:00:00") # start date of data
end <- ymd_hms("2018-06-15 00:00:00") # end date of data
#pull from USGS server
Qdata <- readNWISuv(siteNumbers = sites, parameterCd = "00060", # discharge
startDate = start, endDate = end, tz = "America/Chicago")
Qdata <- renameNWISColumns(Qdata)
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
Qdata$Flow_Inst <- ft3s_m3s(Qdata$Flow_Inst) # convert to SI units
Qdata$dateTime <- ymd_hms(Qdata$dateTime) # report date in lubridate format
Qdata <- Qdata[c(-1,-5,-6)] # take out the columns that report data quality codes
if(avg.Q == TRUE){
Qdata <- # if daily averages are requested, take the flow data and compute an average value for each day
Qdata %>%
group_by(site_no, dateTime = floor_date(dateTime, "day")) %>%
summarize(mean.Q = mean(Flow_Inst))
Qdata <- ymd(Qdata$dateTime) # report date in lubridate format
}
Qdata <- spread(Qdata, site_no, mean.Q) #reorganize the dataframe so each site is in its own column
names(Qdata)[names(Qdata)=="06891080"] <- "Q1.lawrence"
names(Qdata)[names(Qdata)=="06891500"] <- "Q3.wakarusa"
names(Qdata)[names(Qdata)=="06892000"] <- "Q4.stranger"
names(Qdata)[names(Qdata)=="06892350"] <- "Q5.desoto"
# read in flow data from farmland report
FarmlandReport <- read.csv("FarmlandDailyReport_MCKformatted.csv", header = TRUE, stringsAsFactors = FALSE)
Q2.Farmland <- FarmlandReport[c(-2:-8, -10:-11)]
Q2.Farmland$Date <- mdy(Q2.Farmland$Date)
Q2.Farmland <- Q2.Farmland[Q2.Farmland$Date >= ymd("2018-01-01"),] # only look at Jan 1 onwards
# convert from gpm to m3s
gpm_m3s <- function(gpm){
m3s <- gpm*0.000063090196
return(m3s)
}
Q2.Farmland$flowRate_Outfall001A_gpm <- gpm_m3s(Q2.Farmland$flowRate_Outfall001A_gpm)
# merge Q2 with rest of Qdata.avg
Qdata <- merge(Qdata, Q2.Farmland, by.x = "dateTime", by.y = "Date", all = TRUE)
names(Qdata)[names(Qdata)=="flowRate_Outfall001A_gpm"] <- "Q2.Farmland"
# pumping stops on apr 1
Qdata$Q2.Farmland[Qdata$day > ymd("2018-04-01")] <- NULL
#change na values to null
Qdata[is.na(Qdata)] <- NULL
# balance equation: Q5.desoto = Q1.lawrence + Q2.farmland + Q3.wakarusa + Q4.stranger
Qdata$upstreamSum <- Qdata$Q1.lawrence + Qdata$Q2.Farmland + Qdata$Q3.wakarusa + Qdata$Q4.stranger
# calculate amount off that the sum of upstream values is from downstream value
Qdata$waterBal_percentDev <- ((Qdata$Q5.desoto - Qdata$upstreamSum) / Qdata$upstreamSum)*100
if(Q.avg == TRUE){
write.csv(Qdata, "KAWN_USGSDischarge_dailymeans.csv", row.names = FALSE)
} else{
write.csv(Qdata, "KAWN_USGSDischarge_instantaneous.csv", row.names = FALSE)
}
return(Qdata)
}
Qdata.avg <- Q.dataframe(Q.avg = TRUE)
# avg.Q: logical, TRUE returns dataframe of mean daily Q at all sites, FALSE returns all measurements of Q at all sites
# load from file: logical, if TRUE loads appropriate dataframe from file
Q.dataframe <- function(avg.Q){
if(avg.Q == TRUE && file.exists("KAWN_USGSDischarge_dailymeans.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_dailymeans.csv", header = TRUE)
}
if(avg.Q == FALSE && file.exists("KAWN_USGSDischarge_instantaneous.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_instantaneous.csv", header = TRUE)
}
if(!file.exists("KAWN_USGSDischarge_dailymeans.csv") | !file.exists(file.exists("KAWN_USGSDischarge_dailymeans.csv"))){
Q1.lawrence <- "06891080" # USGS identifier codes for gauges of interest
Q3.wakarusa <- "06891500"
Q4.stranger <- "06892000"
Q5.desoto <- "06892350"
sites <- c(Q1.lawrence, Q3.wakarusa, Q4.stranger, Q5.desoto)
start <- ymd_hms("2018-01-01 00:00:00") # start date of data
end <- ymd_hms("2018-06-15 00:00:00") # end date of data
#pull from USGS server
Qdata <- readNWISuv(siteNumbers = sites, parameterCd = "00060", # discharge
startDate = start, endDate = end, tz = "America/Chicago")
Qdata <- renameNWISColumns(Qdata)
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
Qdata$Flow_Inst <- ft3s_m3s(Qdata$Flow_Inst) # convert to SI units
Qdata$dateTime <- ymd_hms(Qdata$dateTime) # report date in lubridate format
Qdata <- Qdata[c(-1,-5,-6)] # take out the columns that report data quality codes
if(avg.Q == TRUE){
Qdata <- # if daily averages are requested, take the flow data and compute an average value for each day
Qdata %>%
group_by(site_no, dateTime = floor_date(dateTime, "day")) %>%
summarize(mean.Q = mean(Flow_Inst))
Qdata <- ymd(Qdata$dateTime) # report date in lubridate format
}
Qdata <- spread(Qdata, site_no, mean.Q) #reorganize the dataframe so each site is in its own column
names(Qdata)[names(Qdata)=="06891080"] <- "Q1.lawrence"
names(Qdata)[names(Qdata)=="06891500"] <- "Q3.wakarusa"
names(Qdata)[names(Qdata)=="06892000"] <- "Q4.stranger"
names(Qdata)[names(Qdata)=="06892350"] <- "Q5.desoto"
# read in flow data from farmland report
FarmlandReport <- read.csv("FarmlandDailyReport_MCKformatted.csv", header = TRUE, stringsAsFactors = FALSE)
Q2.Farmland <- FarmlandReport[c(-2:-8, -10:-11)]
Q2.Farmland$Date <- mdy(Q2.Farmland$Date)
Q2.Farmland <- Q2.Farmland[Q2.Farmland$Date >= ymd("2018-01-01"),] # only look at Jan 1 onwards
# convert from gpm to m3s
gpm_m3s <- function(gpm){
m3s <- gpm*0.000063090196
return(m3s)
}
Q2.Farmland$flowRate_Outfall001A_gpm <- gpm_m3s(Q2.Farmland$flowRate_Outfall001A_gpm)
# merge Q2 with rest of Qdata.avg
Qdata <- merge(Qdata, Q2.Farmland, by.x = "dateTime", by.y = "Date", all = TRUE)
names(Qdata)[names(Qdata)=="flowRate_Outfall001A_gpm"] <- "Q2.Farmland"
# pumping stops on apr 1
Qdata$Q2.Farmland[Qdata$day > ymd("2018-04-01")] <- NULL
#change na values to null
Qdata[is.na(Qdata)] <- NULL
# balance equation: Q5.desoto = Q1.lawrence + Q2.farmland + Q3.wakarusa + Q4.stranger
Qdata$upstreamSum <- Qdata$Q1.lawrence + Qdata$Q2.Farmland + Qdata$Q3.wakarusa + Qdata$Q4.stranger
# calculate amount off that the sum of upstream values is from downstream value
Qdata$waterBal_percentDev <- ((Qdata$Q5.desoto - Qdata$upstreamSum) / Qdata$upstreamSum)*100
if(Q.avg == TRUE){
write.csv(Qdata, "KAWN_USGSDischarge_dailymeans.csv", row.names = FALSE)
} else{
write.csv(Qdata, "KAWN_USGSDischarge_instantaneous.csv", row.names = FALSE)
}
return(Qdata)
}
Qdata.avg <- Q.dataframe(Q.avg = TRUE)
# avg.Q: logical, TRUE returns dataframe of mean daily Q at all sites, FALSE returns all measurements of Q at all sites
# load from file: logical, if TRUE loads appropriate dataframe from file
Q.dataframe <- function(avg.Q){
if(avg.Q = TRUE && file.exists("KAWN_USGSDischarge_dailymeans.csv")){
# avg.Q: logical, TRUE returns dataframe of mean daily Q at all sites, FALSE returns all measurements of Q at all sites
# load from file: logical, if TRUE loads appropriate dataframe from file
Q.dataframe <- function(avg.Q){
if(avg.Q == "TRUE" && file.exists("KAWN_USGSDischarge_dailymeans.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_dailymeans.csv", header = TRUE)
}
if(avg.Q == "FALSE" && file.exists("KAWN_USGSDischarge_instantaneous.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_instantaneous.csv", header = TRUE)
}
if(!file.exists("KAWN_USGSDischarge_dailymeans.csv") | !file.exists(file.exists("KAWN_USGSDischarge_dailymeans.csv"))){
Q1.lawrence <- "06891080" # USGS identifier codes for gauges of interest
Q3.wakarusa <- "06891500"
Q4.stranger <- "06892000"
Q5.desoto <- "06892350"
sites <- c(Q1.lawrence, Q3.wakarusa, Q4.stranger, Q5.desoto)
start <- ymd_hms("2018-01-01 00:00:00") # start date of data
end <- ymd_hms("2018-06-15 00:00:00") # end date of data
#pull from USGS server
Qdata <- readNWISuv(siteNumbers = sites, parameterCd = "00060", # discharge
startDate = start, endDate = end, tz = "America/Chicago")
Qdata <- renameNWISColumns(Qdata)
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
Qdata$Flow_Inst <- ft3s_m3s(Qdata$Flow_Inst) # convert to SI units
Qdata$dateTime <- ymd_hms(Qdata$dateTime) # report date in lubridate format
Qdata <- Qdata[c(-1,-5,-6)] # take out the columns that report data quality codes
if(avg.Q == "TRUE"){
Qdata <- # if daily averages are requested, take the flow data and compute an average value for each day
Qdata %>%
group_by(site_no, dateTime = floor_date(dateTime, "day")) %>%
summarize(mean.Q = mean(Flow_Inst))
Qdata <- ymd(Qdata$dateTime) # report date in lubridate format
}
Qdata <- spread(Qdata, site_no, mean.Q) #reorganize the dataframe so each site is in its own column
names(Qdata)[names(Qdata)=="06891080"] <- "Q1.lawrence"
names(Qdata)[names(Qdata)=="06891500"] <- "Q3.wakarusa"
names(Qdata)[names(Qdata)=="06892000"] <- "Q4.stranger"
names(Qdata)[names(Qdata)=="06892350"] <- "Q5.desoto"
# read in flow data from farmland report
FarmlandReport <- read.csv("FarmlandDailyReport_MCKformatted.csv", header = TRUE, stringsAsFactors = FALSE)
Q2.Farmland <- FarmlandReport[c(-2:-8, -10:-11)]
Q2.Farmland$Date <- mdy(Q2.Farmland$Date)
Q2.Farmland <- Q2.Farmland[Q2.Farmland$Date >= ymd("2018-01-01"),] # only look at Jan 1 onwards
# convert from gpm to m3s
gpm_m3s <- function(gpm){
m3s <- gpm*0.000063090196
return(m3s)
}
Q2.Farmland$flowRate_Outfall001A_gpm <- gpm_m3s(Q2.Farmland$flowRate_Outfall001A_gpm)
# merge Q2 with rest of Qdata.avg
Qdata <- merge(Qdata, Q2.Farmland, by.x = "dateTime", by.y = "Date", all = TRUE)
names(Qdata)[names(Qdata)=="flowRate_Outfall001A_gpm"] <- "Q2.Farmland"
# pumping stops on apr 1
Qdata$Q2.Farmland[Qdata$day > ymd("2018-04-01")] <- NULL
#change na values to null
Qdata[is.na(Qdata)] <- NULL
# balance equation: Q5.desoto = Q1.lawrence + Q2.farmland + Q3.wakarusa + Q4.stranger
Qdata$upstreamSum <- Qdata$Q1.lawrence + Qdata$Q2.Farmland + Qdata$Q3.wakarusa + Qdata$Q4.stranger
# calculate amount off that the sum of upstream values is from downstream value
Qdata$waterBal_percentDev <- ((Qdata$Q5.desoto - Qdata$upstreamSum) / Qdata$upstreamSum)*100
if(Q.avg == "TRUE"){
write.csv(Qdata, "KAWN_USGSDischarge_dailymeans.csv", row.names = FALSE)
} else{
write.csv(Qdata, "KAWN_USGSDischarge_instantaneous.csv", row.names = FALSE)
}
return(Qdata)
}
Qdata.avg <- Q.dataframe(Q.avg = TRUE)
Qdata.avg <- Q.dataframe(Q.avg = "TRUE")
# avg.Q: logical, TRUE returns dataframe of mean daily Q at all sites, FALSE returns all measurements of Q at all sites
# load from file: logical, if TRUE loads appropriate dataframe from file
Q.dataframe <- function(avg.Q){
if(avg.Q == "TRUE" & file.exists("KAWN_USGSDischarge_dailymeans.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_dailymeans.csv", header = TRUE)
}
if(avg.Q == "FALSE" & file.exists("KAWN_USGSDischarge_instantaneous.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_instantaneous.csv", header = TRUE)
}
if(!file.exists("KAWN_USGSDischarge_dailymeans.csv") | !file.exists(file.exists("KAWN_USGSDischarge_dailymeans.csv"))){
Q1.lawrence <- "06891080" # USGS identifier codes for gauges of interest
Q3.wakarusa <- "06891500"
Q4.stranger <- "06892000"
Q5.desoto <- "06892350"
sites <- c(Q1.lawrence, Q3.wakarusa, Q4.stranger, Q5.desoto)
start <- ymd_hms("2018-01-01 00:00:00") # start date of data
end <- ymd_hms("2018-06-15 00:00:00") # end date of data
#pull from USGS server
Qdata <- readNWISuv(siteNumbers = sites, parameterCd = "00060", # discharge
startDate = start, endDate = end, tz = "America/Chicago")
Qdata <- renameNWISColumns(Qdata)
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
Qdata$Flow_Inst <- ft3s_m3s(Qdata$Flow_Inst) # convert to SI units
Qdata$dateTime <- ymd_hms(Qdata$dateTime) # report date in lubridate format
Qdata <- Qdata[c(-1,-5,-6)] # take out the columns that report data quality codes
if(avg.Q == "TRUE"){
Qdata <- # if daily averages are requested, take the flow data and compute an average value for each day
Qdata %>%
group_by(site_no, dateTime = floor_date(dateTime, "day")) %>%
summarize(mean.Q = mean(Flow_Inst))
Qdata <- ymd(Qdata$dateTime) # report date in lubridate format
}
Qdata <- spread(Qdata, site_no, mean.Q) #reorganize the dataframe so each site is in its own column
names(Qdata)[names(Qdata)=="06891080"] <- "Q1.lawrence"
names(Qdata)[names(Qdata)=="06891500"] <- "Q3.wakarusa"
names(Qdata)[names(Qdata)=="06892000"] <- "Q4.stranger"
names(Qdata)[names(Qdata)=="06892350"] <- "Q5.desoto"
# read in flow data from farmland report
FarmlandReport <- read.csv("FarmlandDailyReport_MCKformatted.csv", header = TRUE, stringsAsFactors = FALSE)
Q2.Farmland <- FarmlandReport[c(-2:-8, -10:-11)]
Q2.Farmland$Date <- mdy(Q2.Farmland$Date)
Q2.Farmland <- Q2.Farmland[Q2.Farmland$Date >= ymd("2018-01-01"),] # only look at Jan 1 onwards
# convert from gpm to m3s
gpm_m3s <- function(gpm){
m3s <- gpm*0.000063090196
return(m3s)
}
Q2.Farmland$flowRate_Outfall001A_gpm <- gpm_m3s(Q2.Farmland$flowRate_Outfall001A_gpm)
# merge Q2 with rest of Qdata.avg
Qdata <- merge(Qdata, Q2.Farmland, by.x = "dateTime", by.y = "Date", all = TRUE)
names(Qdata)[names(Qdata)=="flowRate_Outfall001A_gpm"] <- "Q2.Farmland"
# pumping stops on apr 1
Qdata$Q2.Farmland[Qdata$day > ymd("2018-04-01")] <- NULL
#change na values to null
Qdata[is.na(Qdata)] <- NULL
# balance equation: Q5.desoto = Q1.lawrence + Q2.farmland + Q3.wakarusa + Q4.stranger
Qdata$upstreamSum <- Qdata$Q1.lawrence + Qdata$Q2.Farmland + Qdata$Q3.wakarusa + Qdata$Q4.stranger
# calculate amount off that the sum of upstream values is from downstream value
Qdata$waterBal_percentDev <- ((Qdata$Q5.desoto - Qdata$upstreamSum) / Qdata$upstreamSum)*100
if(Q.avg == "TRUE"){
write.csv(Qdata, "KAWN_USGSDischarge_dailymeans.csv", row.names = FALSE)
} else{
write.csv(Qdata, "KAWN_USGSDischarge_instantaneous.csv", row.names = FALSE)
}
return(Qdata)
}
Qdata.avg <- Q.dataframe(Q.avg = "TRUE")
Qdata.avg <- Q.dataframe(avg.Q = TRUE)
# avg.Q: logical, TRUE returns dataframe of mean daily Q at all sites, FALSE returns all measurements of Q at all sites
# load from file: logical, if TRUE loads appropriate dataframe from file
Q.dataframe <- function(avg.Q){
if(avg.Q == "TRUE" & file.exists("KAWN_USGSDischarge_dailymeans.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_dailymeans.csv", header = TRUE)
}
if(avg.Q == "FALSE" & file.exists("KAWN_USGSDischarge_instantaneous.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_instantaneous.csv", header = TRUE)
}
if(!file.exists("KAWN_USGSDischarge_dailymeans.csv") | !file.exists("KAWN_USGSDischarge_dailymeans.csv")){
Q1.lawrence <- "06891080" # USGS identifier codes for gauges of interest
Q3.wakarusa <- "06891500"
Q4.stranger <- "06892000"
Q5.desoto <- "06892350"
sites <- c(Q1.lawrence, Q3.wakarusa, Q4.stranger, Q5.desoto)
start <- ymd_hms("2018-01-01 00:00:00") # start date of data
end <- ymd_hms("2018-06-15 00:00:00") # end date of data
#pull from USGS server
Qdata <- readNWISuv(siteNumbers = sites, parameterCd = "00060", # discharge
startDate = start, endDate = end, tz = "America/Chicago")
Qdata <- renameNWISColumns(Qdata)
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
Qdata$Flow_Inst <- ft3s_m3s(Qdata$Flow_Inst) # convert to SI units
Qdata$dateTime <- ymd_hms(Qdata$dateTime) # report date in lubridate format
Qdata <- Qdata[c(-1,-5,-6)] # take out the columns that report data quality codes
if(avg.Q == "TRUE"){
Qdata <- # if daily averages are requested, take the flow data and compute an average value for each day
Qdata %>%
group_by(site_no, dateTime = floor_date(dateTime, "day")) %>%
summarize(mean.Q = mean(Flow_Inst))
Qdata <- ymd(Qdata$dateTime) # report date in lubridate format
}
Qdata <- spread(Qdata, site_no, mean.Q) #reorganize the dataframe so each site is in its own column
names(Qdata)[names(Qdata)=="06891080"] <- "Q1.lawrence"
names(Qdata)[names(Qdata)=="06891500"] <- "Q3.wakarusa"
names(Qdata)[names(Qdata)=="06892000"] <- "Q4.stranger"
names(Qdata)[names(Qdata)=="06892350"] <- "Q5.desoto"
# read in flow data from farmland report
FarmlandReport <- read.csv("FarmlandDailyReport_MCKformatted.csv", header = TRUE, stringsAsFactors = FALSE)
Q2.Farmland <- FarmlandReport[c(-2:-8, -10:-11)]
Q2.Farmland$Date <- mdy(Q2.Farmland$Date)
Q2.Farmland <- Q2.Farmland[Q2.Farmland$Date >= ymd("2018-01-01"),] # only look at Jan 1 onwards
# convert from gpm to m3s
gpm_m3s <- function(gpm){
m3s <- gpm*0.000063090196
return(m3s)
}
Q2.Farmland$flowRate_Outfall001A_gpm <- gpm_m3s(Q2.Farmland$flowRate_Outfall001A_gpm)
# merge Q2 with rest of Qdata.avg
Qdata <- merge(Qdata, Q2.Farmland, by.x = "dateTime", by.y = "Date", all = TRUE)
names(Qdata)[names(Qdata)=="flowRate_Outfall001A_gpm"] <- "Q2.Farmland"
# pumping stops on apr 1
Qdata$Q2.Farmland[Qdata$day > ymd("2018-04-01")] <- NULL
#change na values to null
Qdata[is.na(Qdata)] <- NULL
# balance equation: Q5.desoto = Q1.lawrence + Q2.farmland + Q3.wakarusa + Q4.stranger
Qdata$upstreamSum <- Qdata$Q1.lawrence + Qdata$Q2.Farmland + Qdata$Q3.wakarusa + Qdata$Q4.stranger
# calculate amount off that the sum of upstream values is from downstream value
Qdata$waterBal_percentDev <- ((Qdata$Q5.desoto - Qdata$upstreamSum) / Qdata$upstreamSum)*100
if(Q.avg == "TRUE"){
write.csv(Qdata, "KAWN_USGSDischarge_dailymeans.csv", row.names = FALSE)
} else{
write.csv(Qdata, "KAWN_USGSDischarge_instantaneous.csv", row.names = FALSE)
}
return(Qdata)
}
# avg.Q: logical, TRUE returns dataframe of mean daily Q at all sites, FALSE returns all measurements of Q at all sites
# load from file: logical, if TRUE loads appropriate dataframe from file
Q.dataframe <- function(avg.Q){
if(avg.Q == TRUE & file.exists("KAWN_USGSDischarge_dailymeans.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_dailymeans.csv", header = TRUE)
}
if(avg.Q == FALSE & file.exists("KAWN_USGSDischarge_instantaneous.csv")){
Qdata <- read.csv("KAWN_USGSDischarge_instantaneous.csv", header = TRUE)
}
if(!file.exists("KAWN_USGSDischarge_dailymeans.csv") | !file.exists("KAWN_USGSDischarge_dailymeans.csv")){
Q1.lawrence <- "06891080" # USGS identifier codes for gauges of interest
Q3.wakarusa <- "06891500"
Q4.stranger <- "06892000"
Q5.desoto <- "06892350"
sites <- c(Q1.lawrence, Q3.wakarusa, Q4.stranger, Q5.desoto)
start <- ymd_hms("2018-01-01 00:00:00") # start date of data
end <- ymd_hms("2018-06-15 00:00:00") # end date of data
#pull from USGS server
Qdata <- readNWISuv(siteNumbers = sites, parameterCd = "00060", # discharge
startDate = start, endDate = end, tz = "America/Chicago")
Qdata <- renameNWISColumns(Qdata)
ft3s_m3s <- function(ft3s){
m3s <- ft3s*0.0283168
return(m3s)
}
Qdata$Flow_Inst <- ft3s_m3s(Qdata$Flow_Inst) # convert to SI units
Qdata$dateTime <- ymd_hms(Qdata$dateTime) # report date in lubridate format
Qdata <- Qdata[c(-1,-5,-6)] # take out the columns that report data quality codes
if(avg.Q == TRUE){
Qdata <- # if daily averages are requested, take the flow data and compute an average value for each day
Qdata %>%
group_by(site_no, dateTime = floor_date(dateTime, "day")) %>%
summarize(mean.Q = mean(Flow_Inst))
Qdata <- ymd(Qdata$dateTime) # report date in lubridate format
}
Qdata <- spread(Qdata, site_no, mean.Q) #reorganize the dataframe so each site is in its own column
names(Qdata)[names(Qdata)=="06891080"] <- "Q1.lawrence"
names(Qdata)[names(Qdata)=="06891500"] <- "Q3.wakarusa"
names(Qdata)[names(Qdata)=="06892000"] <- "Q4.stranger"
names(Qdata)[names(Qdata)=="06892350"] <- "Q5.desoto"
# read in flow data from farmland report
FarmlandReport <- read.csv("FarmlandDailyReport_MCKformatted.csv", header = TRUE, stringsAsFactors = FALSE)
Q2.Farmland <- FarmlandReport[c(-2:-8, -10:-11)]
Q2.Farmland$Date <- mdy(Q2.Farmland$Date)
Q2.Farmland <- Q2.Farmland[Q2.Farmland$Date >= ymd("2018-01-01"),] # only look at Jan 1 onwards
# convert from gpm to m3s
gpm_m3s <- function(gpm){
m3s <- gpm*0.000063090196
return(m3s)
}
Q2.Farmland$flowRate_Outfall001A_gpm <- gpm_m3s(Q2.Farmland$flowRate_Outfall001A_gpm)
# merge Q2 with rest of Qdata.avg
Qdata <- merge(Qdata, Q2.Farmland, by.x = "dateTime", by.y = "Date", all = TRUE)
names(Qdata)[names(Qdata)=="flowRate_Outfall001A_gpm"] <- "Q2.Farmland"
# pumping stops on apr 1
Qdata$Q2.Farmland[Qdata$day > ymd("2018-04-01")] <- NULL
#change na values to null
Qdata[is.na(Qdata)] <- NULL
# balance equation: Q5.desoto = Q1.lawrence + Q2.farmland + Q3.wakarusa + Q4.stranger
Qdata$upstreamSum <- Qdata$Q1.lawrence + Qdata$Q2.Farmland + Qdata$Q3.wakarusa + Qdata$Q4.stranger
# calculate amount off that the sum of upstream values is from downstream value
Qdata$waterBal_percentDev <- ((Qdata$Q5.desoto - Qdata$upstreamSum) / Qdata$upstreamSum)*100
if(Q.avg == "TRUE"){
write.csv(Qdata, "KAWN_USGSDischarge_dailymeans.csv", row.names = FALSE)
} else{
write.csv(Qdata, "KAWN_USGSDischarge_instantaneous.csv", row.names = FALSE)
}
return(Qdata)
}
Qdata.avg <- Q.dataframe(avg.Q = TRUE)
