---
title: 'KAWN: Data loading and cleaning'
author: "Michelle Catherine Kelly"
date: "3 June 2018"
output:
  html_notebook
---

```{r setup, echo = FALSE, warning=FALSE, error=FALSE, message=FALSE}
knitr::opts_chunk$set(cache=TRUE)

library(XML)
library(lubridate)
library(data.table)
library(dataRetrieval) # USGS loading
# NEON loading
# library(devtools)
# install_github("NEONScience/NEON-utilities/neonUtilities", dependencies = TRUE)
library(neonUtilities)
library(SWATmodel)
```

```{r dataLoad}
# masterFile
  # concatenates local nitratax, miniDOT files into a single master .csv (if no master exists). If data is located on USGS database, pulls from USGS database and saves local master. If local master is present, script loads from file
  # sitename = character vector with proper capitalization
  # USGS = logical vector, if TRUE data should is pulled from USGS, if FALSE data is loaded from local files

masterFile <- function(sitename, USGS){
  
  if(file.exists(paste("KAWN_SensorData_", sitename, ".csv", sep = ""))){
    # if master file exists, load from master file
    dataframe <- read.csv(paste("KAWN_SensorData_", sitename, ".csv", sep = ""), 
                          header = TRUE)
  }
  
  if(!file.exists(paste("KAWN_SensorData_", sitename, ".csv", sep = ""))){ 
    # if master file doesn't exist, compile master file
    if(USGS == FALSE){ 
      # load in nitratax data
      nitratax_XMLtoCSV <- function(filename){
        xmlData <- XML::xmlParse(file = filename)
        xmlData <- XML::xmlToDataFrame(xmlData, homogeneous = F, stringsAsFactors = F)
        xmlData <- xmlData[-(1:6),] # taking out text at top of dataframe
        for (count in 1:length(xmlData)){
          names(xmlData)[count] <- as.character(xmlData[1,count])
        }
        xmlData <- xmlData[-1,] # taking out character rows
        xmlData <- xmlData[,-1] # taking out first blank column
        xmlData$`  TIME  ` <- lubridate::as_datetime(xmlData$`  TIME  `, 
                                                     tz = "America/Chicago",
                                                     format = "%m/%d/%Y %H:%M:%S")
        xmlData$`  NITRATE CONC.  ` <- as.numeric(xmlData$`  NITRATE CONC.  `)
        xmlData$`  ER  ` <- as.numeric(xmlData$`  ER  `)
        xmlData$`  EM  ` <- as.numeric(xmlData$`  EM  `)
        
        xmlData <- data.frame(xmlData$`  TIME  `, xmlData$`  NITRATE CONC.  `)
        names(xmlData) <- c("dateTime", "nitrateNitrite")
        return(xmlData)
      }
      
      nitratax <- nitratax_XMLtoCSV(paste("NITRATAX_", sitename, ".xml", sep = ""))
      
      if(file.exists(paste("miniDOT_", sitename, ".txt", sep = ""))){
      # load in minidot data
        DO <- read.table(file = paste("miniDOT_", sitename, ".txt", sep = ""), 
                         header = TRUE, sep = ",", skip = 8, stringsAsFactors = FALSE, 
                         colClasses = c("numeric", "POSIXct", "POSIXct", "numeric", 
                                        "numeric", "numeric", "numeric", "numeric"),
                         col.names = c("unixTimestamp", "time_UTC", "time_CST", 
                                       "battery_V", "temp_C", "DO_mgL", "DO_sat", "Q"))
        DO <- DO[c(-1, -2, -4, -8)] #drop unix timestamp, time UTC, battery volts, Q
        DO$time_CST <- round_date(DO$time_CST, unit = "5 mins") # round time to nearest 5 min
        
        # merge minidot with nitratax by datetime
        dataframe <- merge(nitratax, DO, by.x = "dateTime", by.y = "time_CST", all = TRUE)
        # save master file
        write.csv(dataframe, row.names = FALSE,
                  file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
        
        } else{
          # save master file with just nitratax
          dataframe <- nitratax
          write.csv(dataframe, row.names = FALSE,
                    file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
          }
      } else{ # use USGS package to pull data from web, then save locally
        start <- ymd_hms("2018-01-01 00:00:00")
        end <- ymd_hms("2018-06-15 00:00:00")
        
        if(sitename == "Desoto"){
          siteNo <- "06892350"
          pCodes <- c("99133", "00060", "00065", "00300", "00301","00010", 
                      "00095", "00400", "32295")
          data <- readNWISuv(siteNumbers = siteNo, parameterCd = pCodes, 
                           startDate = start, endDate = end, tz = "America/Chicago")
        
          # Rename columns from codes to readable names
          data <- renameNWISColumns(data)
          # Fix remaining names that are still parameter codes
          names(data)[names(data)=="00301_Inst"] <- "DO_percentsat" 
          names(data)[names(data)=="99133_Inst"] <- "nitrateNitrite"
          
          # Convert from American to SI units
          # cubic foot per second to m3 per second
          ft3s_m3s <- function(ft3s){
            m3s <- ft3s*0.0283168
            return(m3s)
          }
          # foot to meters
          ft_m <- function(ft){
            m <- 0.3048*ft
            return(m)
          }
          data$Flow_Inst <- ft3s_m3s(data$Flow_Inst)
          data$GH_Inst <- ft_m(data$GH_Inst)
          
          # drop agency code, siteNo, various quality codes
          dataframe <- data[c(-1,-2,-5,-7,-9,-11,-13,-15,-17,-19,-21,-22)]
          
          # add column for UTC time
          dataframe$dateTime_UTC <- dataframe$dateTime + hours(5)
        }
        # save the USGS data locally
        write.csv(dataframe, row.names = FALSE,
                  file = paste("KAWN_SensorData_", sitename, ".csv", sep = ""))
      }
  }
  return(dataframe)
  }

bowersock <- masterFile(sitename = "Bowersock", USGS = FALSE)
eric <- masterFile(sitename = "Eric", USGS = FALSE)
steve <- masterFile(sitename = "Steve", USGS = FALSE)
desoto <- masterFile(sitename = "Desoto", USGS = TRUE)
```

```{r discharge_estimation}
# assemble data frame of water balance Q's
Q1.lawrence <- "06891080"
#Q2.farmland
Q3.wakarusa <- "06891500"
Q4.stranger <- "06892000"
Q5.desoto <- "06892350"
sites <- c(Q1.lawrence, Q3.wakarusa, Q4.stranger, Q5.desoto)

start <- ymd_hms("2018-01-01 00:00:00")
end <- ymd_hms("2018-06-15 00:00:00")

Qdata <- readNWISuv(siteNumbers = sites, parameterCd = "00060", # discharge 
                    startDate = start, endDate = end, tz = "America/Chicago")

```










```{r NEONpullCleanup, include=FALSE, eval=FALSE}
downloadNEONfiles <- FALSE

if (downloadNEONfiles == TRUE){
  dir.create(paste0(getwd(), "/NEONfiles"))
  
  ######## PAR ############
  getPackage(dpID = "DP1.00024.001", site_code = "UKFS",
           year_month = "2018-02", package = "basic",
           savepath = paste(getwd(), "NEONfiles", sep = "/")) # Feb at KU field station
  getPackage(dpID = "DP1.00024.001", site_code = "UKFS",
           year_month = "2018-03", package = "basic",
           savepath = paste(getwd(), "NEONfiles", sep = "/")) # March at KU field station
  #getPackage(dpID = "DP1.00024.001", site_code = "UKFS",
           #year_month = "2018-04", package = "basic",
           #savepath = getwd()) # April at KU field station 
  stackByTable(dpID = "DP1.00024.001", 
               filepath = paste0(getwd(), "/NEONfiles"), 
               savepath = paste0(getwd(), "/NEONfiles"), 
               folder = TRUE)
  
  ######## Barometric pressure ############
  getPackage(dpID = "DP1.00004.001", site_code = "UKFS",
           year_month = "2018-02", package = "basic",
           savepath = paste(getwd(), "NEONfiles", sep = "/")) # Feb at KU field station
  getPackage(dpID = "DP1.00004.001", site_code = "UKFS",
           year_month = "2018-03", package = "basic",
           savepath = paste(getwd(), "NEONfiles", sep = "/")) # March
  #getPackage(dpID = "DP1.00004.001", site_code = "UKFS",
           #year_month = "2018-04", package = "basic",
           #savepath = paste(getwd(), "NEONfiles", sep = "/")) # April
  stackByTable(dpID = "DP1.00004.001", 
               filepath = paste0(getwd(), "/NEONfiles"), 
               savepath = paste0(getwd(), "/NEONfiles"), 
               folder = TRUE)
}

PAR <- read.csv(file = paste0(getwd(), "/NEONfiles", "/stackedFiles", 
                              "/PARPAR_1min.csv"), header = TRUE)
PAR <- subset(PAR, subset = PAR$verticalPosition == 10) # take measurements that are closest to ground
PAR$startDateTime <- ymd_hms(PAR$startDateTime, tz = "America/Chicago")
PAR <- data.frame(
    dateTime = PAR$startDateTime,
    mean = PAR$PARMean,
    min = PAR$PARMinimum,
    max = PAR$PARMaximum,
    var = PAR$PARVariance
)

# PAR units are micromoles per m^2 per second

#### Barometric pressure, units are kPa
BarPress <- read.csv(file = paste0(getwd(), "/NEONfiles", "/stackedFiles", 
                              "/BP_30min.csv"), header = TRUE)
BarPress$startDateTime <- ymd_hms(BarPress$startDateTime, tz = "America/Chicago")
BarPress <- data.frame(
  dateTime = BarPress$startDateTime,
  mean = BarPress$staPresMean,
  min = BarPress$staPresMinimum,
  max = BarPress$staPresMaximum,
  var = BarPress$staPresVariance
)
# convert to mmHg
kpa_mmhg <- function(kpa){
  mmhg <- kpa*7.5006156130264
  return(mmhg)
}
BarPress$mean <- kpa_mmhg(BarPress$mean)
BarPress$min <- kpa_mmhg(BarPress$min)
BarPress$max <- kpa_mmhg(BarPress$max)
BarPress$var <- kpa_mmhg(BarPress$var)
```
